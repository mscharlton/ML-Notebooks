{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set() \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Distributions\n",
    "\n",
    "Goal:  How do we build the Probability Mass Function (discrete) or the Probability Density Function (continuous) for multiple random variables with joint distributions?\n",
    "\n",
    "PMF = $P_{x,y}(x=a, y=b), P_x(x) = \\sum_{0}^y P_x(x,y)$  \n",
    "PMF = $P_{x,y,z}(x=a,y=b,z=c), P_x(x) = \\sum_{0}^y \\sum_{0}^z P_{x,y,z}(x,y,z)$  \n",
    "\n",
    "PDF = $f_{x,y,z}(x=a, y=b, z=c), f_x(x) = \\int_0^y \\int_0^z f_{x,y,z}(x,y,z)*dz*dy$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:  \n",
    "Given multiple variables, $X$ and $Y$, derive the expectation forumla for the sum of $X$ and $Y$, ie - $z = x + y$\n",
    "\n",
    "1. $E[z] = \\sum_{0}^x \\sum_{0}^y (x+y) * P_{x,y}(x,y)  $  \n",
    "\n",
    "2. $E[z] = \\sum_{0}^x \\sum_{0}^y (x*P_{x,y}(x,y) + y*P_{x,y}(x,y)$  \n",
    "\n",
    "3. $E[z] = \\sum_{0}^x \\sum_{0}^y x*P_{x,y}(x,y) + \\sum_{0}^x \\sum_{0}^y y*P_{x,y}(x,y)$  \n",
    "\n",
    "4. $E[z] = \\sum_{0}^x x \\sum_{0}^y P_{x,y}(x,y) + \\sum_{0}^y y \\sum_{0}^x P_{x,y}(x,y)$  \n",
    "\n",
    "5. $E[z] = \\sum_{0}^x x*P_x(x) + \\sum_{0}^y y*P_y(y)$   \n",
    "\n",
    "Note: this works due to the following in step 4:  \n",
    "\n",
    "$P_x(x) = \\sum_{0}^x P_{x,y}(x,y)$  \n",
    "\n",
    "Given #5 above, $E[x+y] = E[x] + E[y]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:  \n",
    "\n",
    "Derive the expectation (mean) formula for the product of two discrete independent random variables.  \n",
    "\n",
    "Given variables x,y, $P_{x,y}(x,y)$  \n",
    "\n",
    "1.  $E[x*y] = \\sum_{0}^x \\sum_{0}^y x*y*P_{x,y}(x,y)$  \n",
    "2.  $E[x*y] = \\sum_{0}^x \\sum_{0}^y x*y * P_x(x) * P_y(y)$  <= only b/c of given independence  \n",
    "3.  $E[x*y] = \\sum_{0}^x x*P_x(x) * \\sum_{0}^y y*P_y(y)$  \n",
    "4.  $E[x*y] = E[x] * E[y]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Gaussian Joint Distribution  \n",
    "\n",
    "For multi-random variables $x_1, x_2, x_3, ...., x_d,$  \n",
    "it is commonly written as vector $\\overrightarrow{x} = [x_1, x_2, x_3, ....., x_d]$  \n",
    "and is used in PMF and PDF like:  \n",
    "\n",
    "$f_{\\overrightarrow{x}}(\\overrightarrow{x})$  \n",
    "\n",
    "For multi-variate Gaussion Joint Distribution, the PDF:  \n",
    "\n",
    "$f_{\\overrightarrow{X}}(\\overrightarrow{x}) = (1 / \\sqrt{(2*\\pi)^d * |C|}) * e^{(-(\\overrightarrow{x} - \\overrightarrow{\\mu})^T*C^{-1}*(\\overrightarrow{x} - \\overrightarrow{\\mu}) / 2)}$    \n",
    "\n",
    "\n",
    "where:  \n",
    "1. $\\overrightarrow{x} = [x_1, x_2, x_3, ...., x_d]$  \n",
    "2. $\\overrightarrow{\\mu} = [\\mu_1, \\mu_2, \\mu_3, ...., \\mu_d]$  \n",
    "3. C is a $C_{dxd}$ positive definite matrix (covariance)   \n",
    "4. $|C|$ is the determinent of matrix $C$  \n",
    "5. $C^{-1}$ is the inverse of matrix C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning Random Variables \n",
    "\n",
    "Recall:  \n",
    "$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$  \n",
    "\n",
    "Thus:  \n",
    "$P_{x,y}(x|y) = \\frac{P_{x,y}(x,y)}{P_y(y)}$  \n",
    "and  \n",
    "$P_{y|\\overrightarrow{x}}(y|\\overrightarrow{x}) = \\frac{P_{\\overrightarrow{x},y}(\\overrightarrow{x},y)}{P_y(y)}$  \n",
    "\n",
    "### Independence of multiple random variables  \n",
    "$P(A \\cap B) = P(A) * P(B)$  \n",
    "$P(x,y) = P(x) * P(y)$  \n",
    "\n",
    "$P(A \\cap B \\cap C) = P(A) * P(B) * P(C)$  \n",
    "$P(x,y,z) = P(x)*P(y)*P(z)$  \n",
    "\n",
    "### Conditional Independence of multiple random variables  \n",
    "Given $P(x_1, x_2)$ != $P(x_1)*P(x_2)$, ie - not independent,  \n",
    "\n",
    "it is possible for conditional independence:  \n",
    "\n",
    "$P(x_1, x_2|y) = P(x_1|y) * P(x_2|y)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variate Bayes Classification  \n",
    "Given:  \n",
    "$\\overrightarrow{x} = [x_1, x_2, x_3, ..., x_d]$  \n",
    "\n",
    "y is a finite discrete random variable  \n",
    "\n",
    "Then:\n",
    "$P_{y|\\overrightarrow{x}}(y|\\overrightarrow{x}) = \\frac{f_{\\overrightarrow{x}|y}(\\overrightarrow{x}|y) * P_y(y)}{f_{\\overrightarrow{x}}(x)}$  \n",
    "\n",
    "The goal is to answer $P_{y|\\overrightarrow{x}}(y|\\overrightarrow{x})$ by modeling $f_{\\overrightarrow{x}|y}(\\overrightarrow{x}|y)$  \n",
    "\n",
    "If we were to model the right-hand side of the equation, that is called Generative Modeling, whereas if the data supports it and we can model the left-hand side of the equation, that is called Discremitative Modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curse of Dimensionality  \n",
    "\n",
    "As random variables (dimensions) increases, the amount of data needed to properly model all of them raises exponentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb87579faaf292edd576e44805c46a5458aa20c84e0e19f716fd0a05d233136e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}